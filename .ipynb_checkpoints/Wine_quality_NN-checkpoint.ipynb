{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn import metrics as m\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mapping dictionary that maps the quality values from 0 to 5\n",
    "quality_mapping = {\n",
    "3: 0, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5}\n",
    "df[\"quality\"] = df[\"quality\"].map(quality_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"acidity_by_Ph\"] = df[\"fixed acidity\"]/df[\"pH\"]\n",
    "df[\"density_sugar\"] = df[\"density\"]/df[\"residual sugar\"]\n",
    "df[\"sulphate_by_chloride\"] = df[\"sulphates\"]/df[\"chlorides\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_vals = abs(corr_matrix[\"quality\"]).sort_values(ascending=False)\n",
    "top8_corr =  corr_vals[1:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                 0.480738\n",
       "volatile acidity        0.391735\n",
       "sulphate_by_chloride    0.363317\n",
       "sulphates               0.270777\n",
       "citric acid             0.233733\n",
       "total sulfur dioxide    0.185404\n",
       "density                 0.173251\n",
       "fixed acidity           0.127766\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top8_corr # we will carry with these attributes for the modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top8_corr = pd.DataFrame(top8_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the atributes that correlate best with the wine quality are alcohol, volatile acicity, sulphates, citric acid, total sufur dioxide, density, fixed acidity and chlorides. We will be using these in the modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To prevent the model from overfitting I decided to remove two attributes which seemed to not have a major importance and correlation with the target (citric acid and fixed acidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top8_corr.drop([\"citric acid\", \"fixed acidity\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top8 = list(top8_corr.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top8.append(\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[list_top8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the selected attributes shown an skewed distribution and possess different scales. We will therefore standarized the data before modeling. But first, lets split the data into the test and train sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Splitting data: \n",
    "First we check the distribution of the target values to see if an stratified split is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a skewed dataset for classification \n",
    "so we may want to stratify the data before split. Furthermore, we will want to use **stratified k-fold cross-validation** (For classification problems).\n",
    "\n",
    "-> There are several choices for selecting the appropriate number of bins. If\n",
    "you have a lot of samples( > 10k, > 100k), then you don’t need to care about the\n",
    "number of bins. Just divide the data into 10 or 20 bins. If you do not have a lot of\n",
    "samples, you can use a simple rule like Sturge’s Rule to calculate the appropriate\n",
    "number of bins.\n",
    "\n",
    "\n",
    "Number of Bins = 1 + log2(N) Where N is the number of samples you have in your dataset. # 12 in our case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the stratification we will use the most correlated attribute (alchohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strater (col_item):\n",
    "    if col_item <= 9.3:\n",
    "        return 1\n",
    "    elif col_item > 9.3 and col_item <= 10:\n",
    "        return 2\n",
    "    elif col_item > 10 and col_item <= 11:\n",
    "        return 3\n",
    "    elif col_item > 11 and col_item <= 12:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"strat\"] = df[\"alcohol\"].apply(strater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in split.split(df, df[\"strat\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"quality\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we go with stratified split then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.drop(\"strat\", axis=1, inplace=True)\n",
    "strat_test_set.drop(\"strat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = strat_train_set.drop(\"quality\", axis=1)\n",
    "y_train_full = strat_train_set[\"quality\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = strat_test_set.drop(\"quality\", axis=1)\n",
    "y_test = strat_test_set[\"quality\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full[300:]\n",
    "X_valid = X_train_full[:300]\n",
    "y_train = y_train_full[300:]\n",
    "y_valid = y_train_full[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 15)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(976, 13)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 13)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Input(shape=(13,)),\n",
    "keras.layers.Dense(100, activation=\"selu\",  kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "keras.layers.Dense(50, activation=\"selu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "keras.layers.Dense(50, activation=\"selu\",  kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "keras.layers.Dense(20, activation=\"selu\",  kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(6, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) compile\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer= keras.optimizers.SGD(lr=0.009),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) track\n",
    "# 1) Let’s start by defining the root log directory we will use for our TensorBoard logs\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "# 2) plus a small function that generates a subdirectory path for the current datetime so that it’s different at every \n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_SGD%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def exponential_decay(lr0, s): # with this piece of code and using decay in the optimizer we are able to use exponential deacay\n",
    "#     # we start with high learning rate (0.01) and decrease  by 10 e very s steps. We can see how this helped reach better accuracy in less time\n",
    "#     def exponential_decay_fn(epoch):\n",
    "#         return lr0 * 0.1**(epoch / s)\n",
    "#     return exponential_decay_fn\n",
    "\n",
    "# exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2720), started 0:09:36 ago. (Use '!kill 2720' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a0a1a5b7e712bd2e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a0a1a5b7e712bd2e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 11384), started 11:06:36 ago. (Use '!kill 11384' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-707f0cab09750409\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-707f0cab09750409\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 2/31 [>.............................] - ETA: 6s - loss: 3.8490 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_begin` time: 0.0039s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.4526s). Check your callbacks.\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 3.1686 - accuracy: 0.4232 - val_loss: 2.8617 - val_accuracy: 0.5333\n",
      "Epoch 2/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.8101 - accuracy: 0.5348 - val_loss: 2.7270 - val_accuracy: 0.5633\n",
      "Epoch 3/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.7179 - accuracy: 0.5553 - val_loss: 2.6867 - val_accuracy: 0.5700\n",
      "Epoch 4/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.6594 - accuracy: 0.5697 - val_loss: 2.6476 - val_accuracy: 0.5567\n",
      "Epoch 5/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.6271 - accuracy: 0.5830 - val_loss: 2.6391 - val_accuracy: 0.5567\n",
      "Epoch 6/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.5856 - accuracy: 0.5953 - val_loss: 2.6030 - val_accuracy: 0.5533\n",
      "Epoch 7/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.5617 - accuracy: 0.5912 - val_loss: 2.5872 - val_accuracy: 0.5667\n",
      "Epoch 8/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.5422 - accuracy: 0.5840 - val_loss: 2.5794 - val_accuracy: 0.5667\n",
      "Epoch 9/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.5227 - accuracy: 0.5943 - val_loss: 2.5498 - val_accuracy: 0.5533\n",
      "Epoch 10/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.4899 - accuracy: 0.5891 - val_loss: 2.5303 - val_accuracy: 0.5700\n",
      "Epoch 11/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.4794 - accuracy: 0.5902 - val_loss: 2.5168 - val_accuracy: 0.5500\n",
      "Epoch 12/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.4273 - accuracy: 0.6127 - val_loss: 2.4857 - val_accuracy: 0.5600\n",
      "Epoch 13/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.4157 - accuracy: 0.6055 - val_loss: 2.4790 - val_accuracy: 0.5667\n",
      "Epoch 14/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.4102 - accuracy: 0.5994 - val_loss: 2.4553 - val_accuracy: 0.5667\n",
      "Epoch 15/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.3836 - accuracy: 0.6014 - val_loss: 2.4381 - val_accuracy: 0.5800\n",
      "Epoch 16/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.3672 - accuracy: 0.5809 - val_loss: 2.4312 - val_accuracy: 0.5600\n",
      "Epoch 17/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.3285 - accuracy: 0.6045 - val_loss: 2.4206 - val_accuracy: 0.5633\n",
      "Epoch 18/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.3172 - accuracy: 0.6260 - val_loss: 2.4053 - val_accuracy: 0.5633\n",
      "Epoch 19/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.3073 - accuracy: 0.6168 - val_loss: 2.3833 - val_accuracy: 0.5733\n",
      "Epoch 20/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.2984 - accuracy: 0.6025 - val_loss: 2.3763 - val_accuracy: 0.5800\n",
      "Epoch 21/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.2843 - accuracy: 0.5902 - val_loss: 2.3503 - val_accuracy: 0.5867\n",
      "Epoch 22/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.2653 - accuracy: 0.6127 - val_loss: 2.3365 - val_accuracy: 0.5700\n",
      "Epoch 23/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.2533 - accuracy: 0.6137 - val_loss: 2.3256 - val_accuracy: 0.5733\n",
      "Epoch 24/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.2259 - accuracy: 0.6240 - val_loss: 2.3179 - val_accuracy: 0.5567\n",
      "Epoch 25/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.2240 - accuracy: 0.6117 - val_loss: 2.2957 - val_accuracy: 0.5867\n",
      "Epoch 26/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.1850 - accuracy: 0.6189 - val_loss: 2.2794 - val_accuracy: 0.5833\n",
      "Epoch 27/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 2.1751 - accuracy: 0.6107 - val_loss: 2.2772 - val_accuracy: 0.5700\n",
      "Epoch 28/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.1770 - accuracy: 0.6127 - val_loss: 2.2567 - val_accuracy: 0.5700\n",
      "Epoch 29/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1445 - accuracy: 0.6189 - val_loss: 2.2403 - val_accuracy: 0.5733\n",
      "Epoch 30/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.1371 - accuracy: 0.6168 - val_loss: 2.2275 - val_accuracy: 0.5933\n",
      "Epoch 31/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1233 - accuracy: 0.6322 - val_loss: 2.2165 - val_accuracy: 0.5567\n",
      "Epoch 32/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1140 - accuracy: 0.6219 - val_loss: 2.2051 - val_accuracy: 0.5767\n",
      "Epoch 33/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1131 - accuracy: 0.6127 - val_loss: 2.2015 - val_accuracy: 0.5700\n",
      "Epoch 34/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0878 - accuracy: 0.6219 - val_loss: 2.1886 - val_accuracy: 0.5633\n",
      "Epoch 35/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0738 - accuracy: 0.6219 - val_loss: 2.1671 - val_accuracy: 0.5733\n",
      "Epoch 36/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0603 - accuracy: 0.6230 - val_loss: 2.1500 - val_accuracy: 0.5867\n",
      "Epoch 37/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.0443 - accuracy: 0.6342 - val_loss: 2.1417 - val_accuracy: 0.5567\n",
      "Epoch 38/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0374 - accuracy: 0.6014 - val_loss: 2.1308 - val_accuracy: 0.5767\n",
      "Epoch 39/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0221 - accuracy: 0.6189 - val_loss: 2.1180 - val_accuracy: 0.5833\n",
      "Epoch 40/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0052 - accuracy: 0.6342 - val_loss: 2.1017 - val_accuracy: 0.5867\n",
      "Epoch 41/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.9937 - accuracy: 0.6301 - val_loss: 2.0940 - val_accuracy: 0.5667\n",
      "Epoch 42/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0014 - accuracy: 0.6066 - val_loss: 2.0891 - val_accuracy: 0.5700\n",
      "Epoch 43/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9825 - accuracy: 0.6168 - val_loss: 2.0697 - val_accuracy: 0.5867\n",
      "Epoch 44/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9709 - accuracy: 0.6301 - val_loss: 2.0559 - val_accuracy: 0.5667\n",
      "Epoch 45/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9486 - accuracy: 0.6117 - val_loss: 2.0461 - val_accuracy: 0.5900\n",
      "Epoch 46/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9447 - accuracy: 0.6076 - val_loss: 2.0377 - val_accuracy: 0.5667\n",
      "Epoch 47/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.9226 - accuracy: 0.6383 - val_loss: 2.0350 - val_accuracy: 0.5800\n",
      "Epoch 48/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.9144 - accuracy: 0.6219 - val_loss: 2.0217 - val_accuracy: 0.5833\n",
      "Epoch 49/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8959 - accuracy: 0.6270 - val_loss: 2.0084 - val_accuracy: 0.5667\n",
      "Epoch 50/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8895 - accuracy: 0.6219 - val_loss: 2.0065 - val_accuracy: 0.5733\n",
      "Epoch 51/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8827 - accuracy: 0.6352 - val_loss: 1.9957 - val_accuracy: 0.5967\n",
      "Epoch 52/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8662 - accuracy: 0.6363 - val_loss: 1.9900 - val_accuracy: 0.5700\n",
      "Epoch 53/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8655 - accuracy: 0.6240 - val_loss: 1.9770 - val_accuracy: 0.5833\n",
      "Epoch 54/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8492 - accuracy: 0.6219 - val_loss: 1.9623 - val_accuracy: 0.5967\n",
      "Epoch 55/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8412 - accuracy: 0.6137 - val_loss: 1.9513 - val_accuracy: 0.5800\n",
      "Epoch 56/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8373 - accuracy: 0.6270 - val_loss: 1.9477 - val_accuracy: 0.5733\n",
      "Epoch 57/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8118 - accuracy: 0.6404 - val_loss: 1.9294 - val_accuracy: 0.5700\n",
      "Epoch 58/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8116 - accuracy: 0.6301 - val_loss: 1.9280 - val_accuracy: 0.5967\n",
      "Epoch 59/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7944 - accuracy: 0.6404 - val_loss: 1.9224 - val_accuracy: 0.5833\n",
      "Epoch 60/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7971 - accuracy: 0.6332 - val_loss: 1.9029 - val_accuracy: 0.5833\n",
      "Epoch 61/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7943 - accuracy: 0.6301 - val_loss: 1.9032 - val_accuracy: 0.5933\n",
      "Epoch 62/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.7728 - accuracy: 0.6322 - val_loss: 1.8887 - val_accuracy: 0.5933\n",
      "Epoch 63/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7678 - accuracy: 0.6270 - val_loss: 1.8925 - val_accuracy: 0.5733\n",
      "Epoch 64/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7668 - accuracy: 0.6301 - val_loss: 1.8730 - val_accuracy: 0.5967\n",
      "Epoch 65/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.6240 - val_loss: 1.8651 - val_accuracy: 0.5700\n",
      "Epoch 66/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7456 - accuracy: 0.6342 - val_loss: 1.8576 - val_accuracy: 0.6000\n",
      "Epoch 67/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7254 - accuracy: 0.6311 - val_loss: 1.8459 - val_accuracy: 0.5933\n",
      "Epoch 68/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7251 - accuracy: 0.6219 - val_loss: 1.8452 - val_accuracy: 0.5700\n",
      "Epoch 69/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7177 - accuracy: 0.6219 - val_loss: 1.8379 - val_accuracy: 0.5867\n",
      "Epoch 70/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6949 - accuracy: 0.6199 - val_loss: 1.8232 - val_accuracy: 0.5900\n",
      "Epoch 71/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7084 - accuracy: 0.6127 - val_loss: 1.8215 - val_accuracy: 0.5733\n",
      "Epoch 72/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7012 - accuracy: 0.6311 - val_loss: 1.8075 - val_accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6853 - accuracy: 0.6342 - val_loss: 1.7976 - val_accuracy: 0.6067\n",
      "Epoch 74/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6737 - accuracy: 0.6270 - val_loss: 1.7983 - val_accuracy: 0.5833\n",
      "Epoch 75/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6630 - accuracy: 0.6383 - val_loss: 1.7964 - val_accuracy: 0.6033\n",
      "Epoch 76/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6700 - accuracy: 0.6342 - val_loss: 1.7907 - val_accuracy: 0.5800\n",
      "Epoch 77/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6635 - accuracy: 0.6240 - val_loss: 1.7722 - val_accuracy: 0.5900\n",
      "Epoch 78/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6362 - accuracy: 0.6332 - val_loss: 1.7655 - val_accuracy: 0.6000\n",
      "Epoch 79/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6299 - accuracy: 0.6434 - val_loss: 1.7617 - val_accuracy: 0.6000\n",
      "Epoch 80/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6360 - accuracy: 0.6322 - val_loss: 1.7497 - val_accuracy: 0.6000\n",
      "Epoch 81/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6186 - accuracy: 0.6301 - val_loss: 1.7475 - val_accuracy: 0.5967\n",
      "Epoch 82/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6113 - accuracy: 0.6311 - val_loss: 1.7405 - val_accuracy: 0.5900\n",
      "Epoch 83/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6153 - accuracy: 0.6209 - val_loss: 1.7270 - val_accuracy: 0.5967\n",
      "Epoch 84/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6132 - accuracy: 0.6363 - val_loss: 1.7162 - val_accuracy: 0.5767\n",
      "Epoch 85/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5984 - accuracy: 0.6322 - val_loss: 1.7214 - val_accuracy: 0.5933\n",
      "Epoch 86/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5898 - accuracy: 0.6373 - val_loss: 1.7055 - val_accuracy: 0.6000\n",
      "Epoch 87/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5767 - accuracy: 0.6230 - val_loss: 1.7051 - val_accuracy: 0.5900\n",
      "Epoch 88/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5715 - accuracy: 0.6414 - val_loss: 1.6966 - val_accuracy: 0.5933\n",
      "Epoch 89/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5688 - accuracy: 0.6301 - val_loss: 1.6922 - val_accuracy: 0.5767\n",
      "Epoch 90/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5721 - accuracy: 0.6291 - val_loss: 1.6914 - val_accuracy: 0.5733\n",
      "Epoch 91/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5560 - accuracy: 0.6301 - val_loss: 1.6812 - val_accuracy: 0.5867\n",
      "Epoch 92/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5459 - accuracy: 0.6332 - val_loss: 1.6783 - val_accuracy: 0.5933\n",
      "Epoch 93/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5360 - accuracy: 0.6455 - val_loss: 1.6784 - val_accuracy: 0.5633\n",
      "Epoch 94/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5388 - accuracy: 0.6301 - val_loss: 1.6607 - val_accuracy: 0.5867\n",
      "Epoch 95/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5298 - accuracy: 0.6281 - val_loss: 1.6517 - val_accuracy: 0.5800\n",
      "Epoch 96/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5230 - accuracy: 0.6240 - val_loss: 1.6517 - val_accuracy: 0.5800\n",
      "Epoch 97/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5213 - accuracy: 0.6260 - val_loss: 1.6482 - val_accuracy: 0.5733\n",
      "Epoch 98/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5152 - accuracy: 0.6352 - val_loss: 1.6383 - val_accuracy: 0.5933\n",
      "Epoch 99/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5125 - accuracy: 0.6301 - val_loss: 1.6350 - val_accuracy: 0.5767\n",
      "Epoch 100/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4969 - accuracy: 0.6322 - val_loss: 1.6228 - val_accuracy: 0.5967\n",
      "Epoch 101/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4867 - accuracy: 0.6434 - val_loss: 1.6196 - val_accuracy: 0.5933\n",
      "Epoch 102/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4941 - accuracy: 0.6301 - val_loss: 1.6142 - val_accuracy: 0.5967\n",
      "Epoch 103/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4768 - accuracy: 0.6291 - val_loss: 1.6076 - val_accuracy: 0.5967\n",
      "Epoch 104/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4748 - accuracy: 0.6311 - val_loss: 1.6105 - val_accuracy: 0.5767\n",
      "Epoch 105/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4799 - accuracy: 0.6209 - val_loss: 1.5943 - val_accuracy: 0.5900\n",
      "Epoch 106/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4570 - accuracy: 0.6404 - val_loss: 1.5887 - val_accuracy: 0.5967\n",
      "Epoch 107/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4566 - accuracy: 0.6281 - val_loss: 1.5844 - val_accuracy: 0.5933\n",
      "Epoch 108/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4584 - accuracy: 0.6260 - val_loss: 1.5767 - val_accuracy: 0.5867\n",
      "Epoch 109/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4599 - accuracy: 0.6250 - val_loss: 1.5705 - val_accuracy: 0.5967\n",
      "Epoch 110/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4372 - accuracy: 0.6342 - val_loss: 1.5844 - val_accuracy: 0.5800\n",
      "Epoch 111/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4404 - accuracy: 0.6322 - val_loss: 1.5688 - val_accuracy: 0.5933\n",
      "Epoch 112/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4327 - accuracy: 0.6270 - val_loss: 1.5720 - val_accuracy: 0.5867\n",
      "Epoch 113/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4226 - accuracy: 0.6383 - val_loss: 1.5644 - val_accuracy: 0.5867\n",
      "Epoch 114/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4329 - accuracy: 0.6270 - val_loss: 1.5539 - val_accuracy: 0.5967\n",
      "Epoch 115/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.6281 - val_loss: 1.5478 - val_accuracy: 0.5900\n",
      "Epoch 116/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4072 - accuracy: 0.6496 - val_loss: 1.5416 - val_accuracy: 0.6000\n",
      "Epoch 117/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4103 - accuracy: 0.6322 - val_loss: 1.5379 - val_accuracy: 0.5933\n",
      "Epoch 118/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4069 - accuracy: 0.6404 - val_loss: 1.5330 - val_accuracy: 0.5833\n",
      "Epoch 119/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.6414 - val_loss: 1.5468 - val_accuracy: 0.5900\n",
      "Epoch 120/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.6332 - val_loss: 1.5315 - val_accuracy: 0.5733\n",
      "Epoch 121/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.6332 - val_loss: 1.5180 - val_accuracy: 0.5800\n",
      "Epoch 122/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3871 - accuracy: 0.6148 - val_loss: 1.5237 - val_accuracy: 0.5600\n",
      "Epoch 123/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3890 - accuracy: 0.6414 - val_loss: 1.5109 - val_accuracy: 0.6000\n",
      "Epoch 124/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3776 - accuracy: 0.6281 - val_loss: 1.5061 - val_accuracy: 0.6033\n",
      "Epoch 125/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3646 - accuracy: 0.6291 - val_loss: 1.5077 - val_accuracy: 0.5767\n",
      "Epoch 126/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3696 - accuracy: 0.6332 - val_loss: 1.5065 - val_accuracy: 0.6033\n",
      "Epoch 127/500\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3671 - accuracy: 0.59 - 0s 2ms/step - loss: 1.3633 - accuracy: 0.6393 - val_loss: 1.4973 - val_accuracy: 0.5933\n",
      "Epoch 128/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3559 - accuracy: 0.6270 - val_loss: 1.4965 - val_accuracy: 0.5967\n",
      "Epoch 129/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3586 - accuracy: 0.6322 - val_loss: 1.4952 - val_accuracy: 0.5833\n",
      "Epoch 130/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3533 - accuracy: 0.6342 - val_loss: 1.4806 - val_accuracy: 0.5933\n",
      "Epoch 131/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3344 - accuracy: 0.6311 - val_loss: 1.4814 - val_accuracy: 0.6000\n",
      "Epoch 132/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3435 - accuracy: 0.6332 - val_loss: 1.4781 - val_accuracy: 0.5967\n",
      "Epoch 133/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3402 - accuracy: 0.6414 - val_loss: 1.4822 - val_accuracy: 0.5733\n",
      "Epoch 134/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3369 - accuracy: 0.6414 - val_loss: 1.4707 - val_accuracy: 0.5867\n",
      "Epoch 135/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3391 - accuracy: 0.6311 - val_loss: 1.4646 - val_accuracy: 0.6033\n",
      "Epoch 136/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3333 - accuracy: 0.6424 - val_loss: 1.4620 - val_accuracy: 0.5833\n",
      "Epoch 137/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3254 - accuracy: 0.6475 - val_loss: 1.4557 - val_accuracy: 0.5767\n",
      "Epoch 138/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3221 - accuracy: 0.6383 - val_loss: 1.4520 - val_accuracy: 0.5800\n",
      "Epoch 139/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3202 - accuracy: 0.6311 - val_loss: 1.4561 - val_accuracy: 0.5867\n",
      "Epoch 140/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3041 - accuracy: 0.6260 - val_loss: 1.4468 - val_accuracy: 0.5967\n",
      "Epoch 141/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3026 - accuracy: 0.6465 - val_loss: 1.4473 - val_accuracy: 0.5800\n",
      "Epoch 142/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2996 - accuracy: 0.6434 - val_loss: 1.4415 - val_accuracy: 0.5800\n",
      "Epoch 143/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2964 - accuracy: 0.6373 - val_loss: 1.4326 - val_accuracy: 0.5900\n",
      "Epoch 144/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.6404 - val_loss: 1.4310 - val_accuracy: 0.5867\n",
      "Epoch 145/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2997 - accuracy: 0.6393 - val_loss: 1.4244 - val_accuracy: 0.5933\n",
      "Epoch 146/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2988 - accuracy: 0.6465 - val_loss: 1.4293 - val_accuracy: 0.5800\n",
      "Epoch 147/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2838 - accuracy: 0.6404 - val_loss: 1.4206 - val_accuracy: 0.6000\n",
      "Epoch 148/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2845 - accuracy: 0.6393 - val_loss: 1.4193 - val_accuracy: 0.5700\n",
      "Epoch 149/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2866 - accuracy: 0.6219 - val_loss: 1.4138 - val_accuracy: 0.5800\n",
      "Epoch 150/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2711 - accuracy: 0.6352 - val_loss: 1.4139 - val_accuracy: 0.5733\n",
      "Epoch 151/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2678 - accuracy: 0.6383 - val_loss: 1.4135 - val_accuracy: 0.5967\n",
      "Epoch 152/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2771 - accuracy: 0.6445 - val_loss: 1.4139 - val_accuracy: 0.5867\n",
      "Epoch 153/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2551 - accuracy: 0.6588 - val_loss: 1.4078 - val_accuracy: 0.5900\n",
      "Epoch 154/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2646 - accuracy: 0.6322 - val_loss: 1.4082 - val_accuracy: 0.5933\n",
      "Epoch 155/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2622 - accuracy: 0.6414 - val_loss: 1.3934 - val_accuracy: 0.5867\n",
      "Epoch 156/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2557 - accuracy: 0.6373 - val_loss: 1.3969 - val_accuracy: 0.5733\n",
      "Epoch 157/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2607 - accuracy: 0.6383 - val_loss: 1.3989 - val_accuracy: 0.5833\n",
      "Epoch 158/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2521 - accuracy: 0.6393 - val_loss: 1.4055 - val_accuracy: 0.5767\n",
      "Epoch 159/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2507 - accuracy: 0.6404 - val_loss: 1.3941 - val_accuracy: 0.5867\n",
      "Epoch 160/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2479 - accuracy: 0.6352 - val_loss: 1.3790 - val_accuracy: 0.6000\n",
      "Epoch 161/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2517 - accuracy: 0.6250 - val_loss: 1.3907 - val_accuracy: 0.6000\n",
      "Epoch 162/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2458 - accuracy: 0.6404 - val_loss: 1.3781 - val_accuracy: 0.5833\n",
      "Epoch 163/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2240 - accuracy: 0.6363 - val_loss: 1.3743 - val_accuracy: 0.5833\n",
      "Epoch 164/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2320 - accuracy: 0.6434 - val_loss: 1.3714 - val_accuracy: 0.6000\n",
      "Epoch 165/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2260 - accuracy: 0.6568 - val_loss: 1.3661 - val_accuracy: 0.5933\n",
      "Epoch 166/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2237 - accuracy: 0.6342 - val_loss: 1.3667 - val_accuracy: 0.5833\n",
      "Epoch 167/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2259 - accuracy: 0.6496 - val_loss: 1.3733 - val_accuracy: 0.5900\n",
      "Epoch 168/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2234 - accuracy: 0.6373 - val_loss: 1.3637 - val_accuracy: 0.5833\n",
      "Epoch 169/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2263 - accuracy: 0.6332 - val_loss: 1.3593 - val_accuracy: 0.6000\n",
      "Epoch 170/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.2177 - accuracy: 0.6363 - val_loss: 1.3545 - val_accuracy: 0.5800\n",
      "Epoch 171/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2162 - accuracy: 0.6414 - val_loss: 1.3499 - val_accuracy: 0.5933\n",
      "Epoch 172/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2184 - accuracy: 0.6434 - val_loss: 1.3559 - val_accuracy: 0.5900\n",
      "Epoch 173/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1992 - accuracy: 0.6475 - val_loss: 1.3477 - val_accuracy: 0.6000\n",
      "Epoch 174/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2057 - accuracy: 0.6393 - val_loss: 1.3443 - val_accuracy: 0.5867\n",
      "Epoch 175/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2059 - accuracy: 0.6393 - val_loss: 1.3403 - val_accuracy: 0.5967\n",
      "Epoch 176/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2002 - accuracy: 0.6506 - val_loss: 1.3471 - val_accuracy: 0.5867\n",
      "Epoch 177/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1871 - accuracy: 0.6475 - val_loss: 1.3386 - val_accuracy: 0.5800\n",
      "Epoch 178/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2028 - accuracy: 0.6363 - val_loss: 1.3321 - val_accuracy: 0.5900\n",
      "Epoch 179/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1951 - accuracy: 0.6537 - val_loss: 1.3363 - val_accuracy: 0.5833\n",
      "Epoch 180/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2020 - accuracy: 0.6424 - val_loss: 1.3347 - val_accuracy: 0.5767\n",
      "Epoch 181/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1875 - accuracy: 0.6557 - val_loss: 1.3221 - val_accuracy: 0.5933\n",
      "Epoch 182/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1847 - accuracy: 0.6516 - val_loss: 1.3295 - val_accuracy: 0.5967\n",
      "Epoch 183/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1771 - accuracy: 0.6537 - val_loss: 1.3351 - val_accuracy: 0.5667\n",
      "Epoch 184/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1831 - accuracy: 0.6404 - val_loss: 1.3324 - val_accuracy: 0.5833\n",
      "Epoch 185/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1792 - accuracy: 0.6506 - val_loss: 1.3279 - val_accuracy: 0.6000\n",
      "Epoch 186/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1766 - accuracy: 0.6352 - val_loss: 1.3262 - val_accuracy: 0.5700\n",
      "Epoch 187/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1629 - accuracy: 0.6434 - val_loss: 1.3180 - val_accuracy: 0.5867\n",
      "Epoch 188/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1738 - accuracy: 0.6527 - val_loss: 1.3192 - val_accuracy: 0.5900\n",
      "Epoch 189/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1648 - accuracy: 0.6455 - val_loss: 1.3114 - val_accuracy: 0.5867\n",
      "Epoch 190/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1613 - accuracy: 0.6496 - val_loss: 1.3072 - val_accuracy: 0.5900\n",
      "Epoch 191/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1547 - accuracy: 0.6475 - val_loss: 1.3116 - val_accuracy: 0.5867\n",
      "Epoch 192/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1616 - accuracy: 0.6434 - val_loss: 1.3126 - val_accuracy: 0.6033\n",
      "Epoch 193/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1623 - accuracy: 0.6475 - val_loss: 1.3142 - val_accuracy: 0.5700\n",
      "Epoch 194/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1612 - accuracy: 0.6465 - val_loss: 1.3035 - val_accuracy: 0.6067\n",
      "Epoch 195/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1566 - accuracy: 0.6404 - val_loss: 1.3084 - val_accuracy: 0.5833\n",
      "Epoch 196/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1493 - accuracy: 0.6424 - val_loss: 1.3026 - val_accuracy: 0.5867\n",
      "Epoch 197/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.1484 - accuracy: 0.6516 - val_loss: 1.3142 - val_accuracy: 0.5933\n",
      "Epoch 198/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1430 - accuracy: 0.6486 - val_loss: 1.2895 - val_accuracy: 0.5900\n",
      "Epoch 199/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1518 - accuracy: 0.6424 - val_loss: 1.2886 - val_accuracy: 0.5933\n",
      "Epoch 200/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1383 - accuracy: 0.6465 - val_loss: 1.2919 - val_accuracy: 0.5900\n",
      "Epoch 201/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1407 - accuracy: 0.6588 - val_loss: 1.2992 - val_accuracy: 0.5900\n",
      "Epoch 202/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1419 - accuracy: 0.6465 - val_loss: 1.2883 - val_accuracy: 0.6100\n",
      "Epoch 203/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1287 - accuracy: 0.6383 - val_loss: 1.2922 - val_accuracy: 0.5967\n",
      "Epoch 204/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1359 - accuracy: 0.6547 - val_loss: 1.2904 - val_accuracy: 0.5833\n",
      "Epoch 205/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1279 - accuracy: 0.6486 - val_loss: 1.2896 - val_accuracy: 0.5900\n",
      "Epoch 206/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1320 - accuracy: 0.6455 - val_loss: 1.2925 - val_accuracy: 0.5967\n",
      "Epoch 207/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1371 - accuracy: 0.6496 - val_loss: 1.2740 - val_accuracy: 0.5933\n",
      "Epoch 208/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1222 - accuracy: 0.6516 - val_loss: 1.2799 - val_accuracy: 0.5967\n",
      "Epoch 209/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1271 - accuracy: 0.6424 - val_loss: 1.2816 - val_accuracy: 0.5667\n",
      "Epoch 210/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1263 - accuracy: 0.6486 - val_loss: 1.2904 - val_accuracy: 0.5833\n",
      "Epoch 211/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1351 - accuracy: 0.6393 - val_loss: 1.2891 - val_accuracy: 0.5567\n",
      "Epoch 212/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1220 - accuracy: 0.6445 - val_loss: 1.2731 - val_accuracy: 0.6167\n",
      "Epoch 213/500\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.1123 - accuracy: 0.6588 - val_loss: 1.2807 - val_accuracy: 0.5533\n",
      "Epoch 214/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1206 - accuracy: 0.6434 - val_loss: 1.2807 - val_accuracy: 0.5800\n",
      "Epoch 215/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1152 - accuracy: 0.6547 - val_loss: 1.2624 - val_accuracy: 0.6067\n",
      "Epoch 216/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1237 - accuracy: 0.6496 - val_loss: 1.2788 - val_accuracy: 0.6000\n",
      "Epoch 217/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1218 - accuracy: 0.6445 - val_loss: 1.2727 - val_accuracy: 0.5967\n",
      "Epoch 218/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1152 - accuracy: 0.6486 - val_loss: 1.2650 - val_accuracy: 0.6000\n",
      "Epoch 219/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1164 - accuracy: 0.6455 - val_loss: 1.2604 - val_accuracy: 0.5800\n",
      "Epoch 220/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1191 - accuracy: 0.6363 - val_loss: 1.2701 - val_accuracy: 0.5800\n",
      "Epoch 221/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1051 - accuracy: 0.6434 - val_loss: 1.2672 - val_accuracy: 0.5667\n",
      "Epoch 222/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1003 - accuracy: 0.6516 - val_loss: 1.2606 - val_accuracy: 0.5733\n",
      "Epoch 223/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0997 - accuracy: 0.6578 - val_loss: 1.2679 - val_accuracy: 0.5833\n",
      "Epoch 224/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0994 - accuracy: 0.6527 - val_loss: 1.2470 - val_accuracy: 0.5900\n",
      "Epoch 225/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0907 - accuracy: 0.6475 - val_loss: 1.2558 - val_accuracy: 0.5967\n",
      "Epoch 226/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1082 - accuracy: 0.6393 - val_loss: 1.2569 - val_accuracy: 0.5967\n",
      "Epoch 227/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0962 - accuracy: 0.6516 - val_loss: 1.2571 - val_accuracy: 0.5900\n",
      "Epoch 228/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0934 - accuracy: 0.6383 - val_loss: 1.2593 - val_accuracy: 0.5900\n",
      "Epoch 229/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0916 - accuracy: 0.6404 - val_loss: 1.2542 - val_accuracy: 0.5867\n",
      "Epoch 230/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0899 - accuracy: 0.6557 - val_loss: 1.2472 - val_accuracy: 0.6033\n",
      "Epoch 231/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0943 - accuracy: 0.6465 - val_loss: 1.2468 - val_accuracy: 0.5800\n",
      "Epoch 232/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0874 - accuracy: 0.6527 - val_loss: 1.2511 - val_accuracy: 0.5867\n",
      "Epoch 233/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0911 - accuracy: 0.6516 - val_loss: 1.2422 - val_accuracy: 0.5767\n",
      "Epoch 234/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0966 - accuracy: 0.6434 - val_loss: 1.2419 - val_accuracy: 0.6200\n",
      "Epoch 235/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0836 - accuracy: 0.6557 - val_loss: 1.2510 - val_accuracy: 0.5633\n",
      "Epoch 236/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0919 - accuracy: 0.6475 - val_loss: 1.2304 - val_accuracy: 0.6133\n",
      "Epoch 237/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0840 - accuracy: 0.6588 - val_loss: 1.2294 - val_accuracy: 0.5900\n",
      "Epoch 238/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0812 - accuracy: 0.6557 - val_loss: 1.2368 - val_accuracy: 0.5667\n",
      "Epoch 239/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0812 - accuracy: 0.6578 - val_loss: 1.2342 - val_accuracy: 0.5967\n",
      "Epoch 240/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0861 - accuracy: 0.6434 - val_loss: 1.2327 - val_accuracy: 0.5967\n",
      "Epoch 241/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.6568 - val_loss: 1.2534 - val_accuracy: 0.5600\n",
      "Epoch 242/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0794 - accuracy: 0.6393 - val_loss: 1.2414 - val_accuracy: 0.5933\n",
      "Epoch 243/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0684 - accuracy: 0.6568 - val_loss: 1.2343 - val_accuracy: 0.5767\n",
      "Epoch 244/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0777 - accuracy: 0.6568 - val_loss: 1.2376 - val_accuracy: 0.5800\n",
      "Epoch 245/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0718 - accuracy: 0.6475 - val_loss: 1.2370 - val_accuracy: 0.5800\n",
      "Epoch 246/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0613 - accuracy: 0.6578 - val_loss: 1.2364 - val_accuracy: 0.5733\n",
      "Epoch 247/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0599 - accuracy: 0.6506 - val_loss: 1.2289 - val_accuracy: 0.6000\n",
      "Epoch 248/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0658 - accuracy: 0.6547 - val_loss: 1.2304 - val_accuracy: 0.5967\n",
      "Epoch 249/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0695 - accuracy: 0.6496 - val_loss: 1.2187 - val_accuracy: 0.5900\n",
      "Epoch 250/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.6568 - val_loss: 1.2297 - val_accuracy: 0.5933\n",
      "Epoch 251/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0604 - accuracy: 0.6506 - val_loss: 1.2146 - val_accuracy: 0.5900\n",
      "Epoch 252/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0583 - accuracy: 0.6619 - val_loss: 1.2237 - val_accuracy: 0.5800\n",
      "Epoch 253/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0681 - accuracy: 0.6537 - val_loss: 1.2161 - val_accuracy: 0.5833\n",
      "Epoch 254/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0660 - accuracy: 0.6301 - val_loss: 1.2133 - val_accuracy: 0.5867\n",
      "Epoch 255/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0536 - accuracy: 0.6557 - val_loss: 1.2227 - val_accuracy: 0.5900\n",
      "Epoch 256/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0591 - accuracy: 0.6506 - val_loss: 1.2146 - val_accuracy: 0.5933\n",
      "Epoch 257/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0575 - accuracy: 0.6650 - val_loss: 1.2192 - val_accuracy: 0.6033\n",
      "Epoch 258/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0620 - accuracy: 0.6537 - val_loss: 1.2164 - val_accuracy: 0.6000\n",
      "Epoch 259/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0603 - accuracy: 0.6609 - val_loss: 1.2146 - val_accuracy: 0.5967\n",
      "Epoch 260/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0493 - accuracy: 0.6537 - val_loss: 1.2488 - val_accuracy: 0.5633\n",
      "Epoch 261/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0592 - accuracy: 0.6465 - val_loss: 1.2040 - val_accuracy: 0.6033\n",
      "Epoch 262/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0496 - accuracy: 0.6639 - val_loss: 1.2221 - val_accuracy: 0.5900\n",
      "Epoch 263/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0532 - accuracy: 0.6537 - val_loss: 1.2122 - val_accuracy: 0.5967\n",
      "Epoch 264/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.6650 - val_loss: 1.2132 - val_accuracy: 0.6033\n",
      "Epoch 265/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.6547 - val_loss: 1.2169 - val_accuracy: 0.5867\n",
      "Epoch 266/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0490 - accuracy: 0.6691 - val_loss: 1.2414 - val_accuracy: 0.5633\n",
      "Epoch 267/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0433 - accuracy: 0.6496 - val_loss: 1.2085 - val_accuracy: 0.6067\n",
      "Epoch 268/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0461 - accuracy: 0.6527 - val_loss: 1.2119 - val_accuracy: 0.5867\n",
      "Epoch 269/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.6506 - val_loss: 1.2037 - val_accuracy: 0.5900\n",
      "Epoch 270/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0412 - accuracy: 0.6547 - val_loss: 1.2168 - val_accuracy: 0.5800\n",
      "Epoch 271/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0499 - accuracy: 0.6537 - val_loss: 1.2138 - val_accuracy: 0.5800\n",
      "Epoch 272/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.6547 - val_loss: 1.2052 - val_accuracy: 0.5967\n",
      "Epoch 273/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0392 - accuracy: 0.6547 - val_loss: 1.2210 - val_accuracy: 0.5633\n",
      "Epoch 274/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0239 - accuracy: 0.6527 - val_loss: 1.2161 - val_accuracy: 0.5767\n",
      "Epoch 275/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.6568 - val_loss: 1.2092 - val_accuracy: 0.6067\n",
      "Epoch 276/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0422 - accuracy: 0.6486 - val_loss: 1.2063 - val_accuracy: 0.5733\n",
      "Epoch 277/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0451 - accuracy: 0.6527 - val_loss: 1.2070 - val_accuracy: 0.5767\n",
      "Epoch 278/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.6363 - val_loss: 1.2131 - val_accuracy: 0.5800\n",
      "Epoch 279/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0412 - accuracy: 0.6537 - val_loss: 1.2137 - val_accuracy: 0.5767\n",
      "Epoch 280/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0325 - accuracy: 0.6445 - val_loss: 1.2125 - val_accuracy: 0.5800\n",
      "Epoch 281/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0324 - accuracy: 0.6516 - val_loss: 1.2252 - val_accuracy: 0.5667\n",
      "Epoch 282/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.6496 - val_loss: 1.2070 - val_accuracy: 0.6100\n",
      "Epoch 283/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0396 - accuracy: 0.6516 - val_loss: 1.2051 - val_accuracy: 0.5833\n",
      "Epoch 284/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0351 - accuracy: 0.6598 - val_loss: 1.2053 - val_accuracy: 0.6000\n",
      "Epoch 285/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.6568 - val_loss: 1.1953 - val_accuracy: 0.6100\n",
      "Epoch 286/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0351 - accuracy: 0.6639 - val_loss: 1.2071 - val_accuracy: 0.5800\n",
      "Epoch 287/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.6516 - val_loss: 1.2038 - val_accuracy: 0.5867\n",
      "Epoch 288/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0351 - accuracy: 0.6619 - val_loss: 1.1971 - val_accuracy: 0.5867\n",
      "Epoch 289/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.6516 - val_loss: 1.1920 - val_accuracy: 0.5933\n",
      "Epoch 290/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.6578 - val_loss: 1.2426 - val_accuracy: 0.5400\n",
      "Epoch 291/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.6670 - val_loss: 1.1841 - val_accuracy: 0.5933\n",
      "Epoch 292/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.6465 - val_loss: 1.1901 - val_accuracy: 0.5900\n",
      "Epoch 293/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0212 - accuracy: 0.6455 - val_loss: 1.1820 - val_accuracy: 0.6000\n",
      "Epoch 294/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0192 - accuracy: 0.6609 - val_loss: 1.1841 - val_accuracy: 0.5900\n",
      "Epoch 295/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0253 - accuracy: 0.6578 - val_loss: 1.2060 - val_accuracy: 0.5800\n",
      "Epoch 296/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0241 - accuracy: 0.6414 - val_loss: 1.1991 - val_accuracy: 0.6067\n",
      "Epoch 297/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0154 - accuracy: 0.6568 - val_loss: 1.2070 - val_accuracy: 0.5600\n",
      "Epoch 298/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.6578 - val_loss: 1.1991 - val_accuracy: 0.5867\n",
      "Epoch 299/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.6434 - val_loss: 1.1913 - val_accuracy: 0.5800\n",
      "Epoch 300/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.6598 - val_loss: 1.1880 - val_accuracy: 0.5667\n",
      "Epoch 301/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0093 - accuracy: 0.6609 - val_loss: 1.1868 - val_accuracy: 0.5767\n",
      "Epoch 302/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0108 - accuracy: 0.6537 - val_loss: 1.1818 - val_accuracy: 0.5900\n",
      "Epoch 303/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.6619 - val_loss: 1.1855 - val_accuracy: 0.5833\n",
      "Epoch 304/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0090 - accuracy: 0.6639 - val_loss: 1.2047 - val_accuracy: 0.5800\n",
      "Epoch 305/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.6486 - val_loss: 1.1876 - val_accuracy: 0.6067\n",
      "Epoch 306/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0114 - accuracy: 0.6568 - val_loss: 1.1819 - val_accuracy: 0.6167\n",
      "Epoch 307/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.6527 - val_loss: 1.1871 - val_accuracy: 0.6033\n",
      "Epoch 308/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0123 - accuracy: 0.6578 - val_loss: 1.2065 - val_accuracy: 0.6033\n",
      "Epoch 309/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0069 - accuracy: 0.6598 - val_loss: 1.1869 - val_accuracy: 0.6033\n",
      "Epoch 310/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.6516 - val_loss: 1.2005 - val_accuracy: 0.5800\n",
      "Epoch 311/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0039 - accuracy: 0.6496 - val_loss: 1.1891 - val_accuracy: 0.5833\n",
      "Epoch 312/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0054 - accuracy: 0.6650 - val_loss: 1.1903 - val_accuracy: 0.5933\n",
      "Epoch 313/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9986 - accuracy: 0.6557 - val_loss: 1.1969 - val_accuracy: 0.6033\n",
      "Epoch 314/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0017 - accuracy: 0.6650 - val_loss: 1.1767 - val_accuracy: 0.5967\n",
      "Epoch 315/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0047 - accuracy: 0.6568 - val_loss: 1.1880 - val_accuracy: 0.5900\n",
      "Epoch 316/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.6619 - val_loss: 1.1993 - val_accuracy: 0.5900\n",
      "Epoch 317/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0047 - accuracy: 0.6650 - val_loss: 1.1959 - val_accuracy: 0.5800\n",
      "Epoch 318/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0058 - accuracy: 0.6486 - val_loss: 1.1854 - val_accuracy: 0.6033\n",
      "Epoch 319/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0011 - accuracy: 0.6619 - val_loss: 1.1860 - val_accuracy: 0.6100\n",
      "Epoch 320/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9977 - accuracy: 0.6537 - val_loss: 1.2110 - val_accuracy: 0.5967\n",
      "Epoch 321/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0030 - accuracy: 0.6516 - val_loss: 1.1742 - val_accuracy: 0.5833\n",
      "Epoch 322/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0014 - accuracy: 0.6557 - val_loss: 1.1941 - val_accuracy: 0.5633\n",
      "Epoch 323/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0023 - accuracy: 0.6650 - val_loss: 1.1771 - val_accuracy: 0.6133\n",
      "Epoch 324/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.6557 - val_loss: 1.1885 - val_accuracy: 0.6167\n",
      "Epoch 325/500\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.0046 - accuracy: 0.6455 - val_loss: 1.1744 - val_accuracy: 0.5967\n",
      "Epoch 326/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9972 - accuracy: 0.6598 - val_loss: 1.1867 - val_accuracy: 0.5733\n",
      "Epoch 327/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9982 - accuracy: 0.6557 - val_loss: 1.1690 - val_accuracy: 0.6100\n",
      "Epoch 328/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9917 - accuracy: 0.6598 - val_loss: 1.1805 - val_accuracy: 0.6100\n",
      "Epoch 329/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9871 - accuracy: 0.6568 - val_loss: 1.1956 - val_accuracy: 0.5967\n",
      "Epoch 330/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0097 - accuracy: 0.6465 - val_loss: 1.1807 - val_accuracy: 0.5833\n",
      "Epoch 331/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9897 - accuracy: 0.6701 - val_loss: 1.1849 - val_accuracy: 0.6200\n",
      "Epoch 332/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0041 - accuracy: 0.6557 - val_loss: 1.1707 - val_accuracy: 0.6033\n",
      "Epoch 333/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0058 - accuracy: 0.6496 - val_loss: 1.1866 - val_accuracy: 0.5700\n",
      "Epoch 334/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9871 - accuracy: 0.6598 - val_loss: 1.1747 - val_accuracy: 0.5833\n",
      "Epoch 335/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9909 - accuracy: 0.6557 - val_loss: 1.1946 - val_accuracy: 0.5833\n",
      "Epoch 336/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.6598 - val_loss: 1.1805 - val_accuracy: 0.5867\n",
      "Epoch 337/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.6516 - val_loss: 1.1972 - val_accuracy: 0.5667\n",
      "Epoch 338/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.6629 - val_loss: 1.1792 - val_accuracy: 0.6000\n",
      "Epoch 339/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.6578 - val_loss: 1.1869 - val_accuracy: 0.5733\n",
      "Epoch 340/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9906 - accuracy: 0.6670 - val_loss: 1.2095 - val_accuracy: 0.5500\n",
      "Epoch 341/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9877 - accuracy: 0.6547 - val_loss: 1.1864 - val_accuracy: 0.5933\n",
      "Epoch 342/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9945 - accuracy: 0.6711 - val_loss: 1.1805 - val_accuracy: 0.6167\n",
      "Epoch 343/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9913 - accuracy: 0.6537 - val_loss: 1.1967 - val_accuracy: 0.5900\n",
      "Epoch 344/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.6496 - val_loss: 1.1994 - val_accuracy: 0.5567\n",
      "Epoch 345/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9925 - accuracy: 0.6557 - val_loss: 1.1687 - val_accuracy: 0.5833\n",
      "Epoch 346/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.6691 - val_loss: 1.1851 - val_accuracy: 0.5600\n",
      "Epoch 347/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.6598 - val_loss: 1.1874 - val_accuracy: 0.5900\n",
      "Epoch 348/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.6475 - val_loss: 1.1979 - val_accuracy: 0.5867\n",
      "Epoch 349/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9923 - accuracy: 0.6609 - val_loss: 1.1640 - val_accuracy: 0.5967\n",
      "Epoch 350/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9900 - accuracy: 0.6609 - val_loss: 1.1723 - val_accuracy: 0.6233\n",
      "Epoch 351/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9835 - accuracy: 0.6527 - val_loss: 1.1751 - val_accuracy: 0.5700\n",
      "Epoch 352/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.6455 - val_loss: 1.1799 - val_accuracy: 0.5867\n",
      "Epoch 353/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9850 - accuracy: 0.6598 - val_loss: 1.1949 - val_accuracy: 0.5700\n",
      "Epoch 354/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9888 - accuracy: 0.6537 - val_loss: 1.2300 - val_accuracy: 0.5300\n",
      "Epoch 355/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9737 - accuracy: 0.6691 - val_loss: 1.1850 - val_accuracy: 0.5700\n",
      "Epoch 356/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9953 - accuracy: 0.6619 - val_loss: 1.1905 - val_accuracy: 0.5867\n",
      "Epoch 357/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.6619 - val_loss: 1.1768 - val_accuracy: 0.5867\n",
      "Epoch 358/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.6598 - val_loss: 1.1896 - val_accuracy: 0.5800\n",
      "Epoch 359/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9747 - accuracy: 0.6568 - val_loss: 1.1820 - val_accuracy: 0.5900\n",
      "Epoch 360/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9733 - accuracy: 0.6475 - val_loss: 1.1923 - val_accuracy: 0.5767\n",
      "Epoch 361/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9829 - accuracy: 0.6547 - val_loss: 1.1763 - val_accuracy: 0.5900\n",
      "Epoch 362/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9823 - accuracy: 0.6639 - val_loss: 1.1773 - val_accuracy: 0.5767\n",
      "Epoch 363/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9830 - accuracy: 0.6527 - val_loss: 1.1936 - val_accuracy: 0.5733\n",
      "Epoch 364/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.6619 - val_loss: 1.1604 - val_accuracy: 0.5867\n",
      "Epoch 365/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9776 - accuracy: 0.6496 - val_loss: 1.2104 - val_accuracy: 0.5633\n",
      "Epoch 366/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9789 - accuracy: 0.6691 - val_loss: 1.1700 - val_accuracy: 0.6067\n",
      "Epoch 367/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9829 - accuracy: 0.6619 - val_loss: 1.1797 - val_accuracy: 0.5867\n",
      "Epoch 368/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9780 - accuracy: 0.6680 - val_loss: 1.1721 - val_accuracy: 0.5833\n",
      "Epoch 369/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9846 - accuracy: 0.6404 - val_loss: 1.2018 - val_accuracy: 0.5767\n",
      "Epoch 370/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.6598 - val_loss: 1.1689 - val_accuracy: 0.5900\n",
      "Epoch 371/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.9770 - accuracy: 0.6619 - val_loss: 1.1734 - val_accuracy: 0.5933\n",
      "Epoch 372/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.9727 - accuracy: 0.6691 - val_loss: 1.1812 - val_accuracy: 0.5733\n",
      "Epoch 373/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9696 - accuracy: 0.6629 - val_loss: 1.2035 - val_accuracy: 0.5700\n",
      "Epoch 374/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9826 - accuracy: 0.6680 - val_loss: 1.1672 - val_accuracy: 0.5833\n",
      "Epoch 375/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9646 - accuracy: 0.6660 - val_loss: 1.1755 - val_accuracy: 0.5900\n",
      "Epoch 376/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9614 - accuracy: 0.6680 - val_loss: 1.2388 - val_accuracy: 0.5167\n",
      "Epoch 377/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.9849 - accuracy: 0.6598 - val_loss: 1.1610 - val_accuracy: 0.5967\n",
      "Epoch 378/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.6609 - val_loss: 1.1818 - val_accuracy: 0.5767\n",
      "Epoch 379/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.6578 - val_loss: 1.1611 - val_accuracy: 0.6000\n",
      "Epoch 380/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.6660 - val_loss: 1.1680 - val_accuracy: 0.5800\n",
      "Epoch 381/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9853 - accuracy: 0.6650 - val_loss: 1.1781 - val_accuracy: 0.6000\n",
      "Epoch 382/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9665 - accuracy: 0.6527 - val_loss: 1.1634 - val_accuracy: 0.5967\n",
      "Epoch 383/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9687 - accuracy: 0.6670 - val_loss: 1.1762 - val_accuracy: 0.6000\n",
      "Epoch 384/500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9649 - accuracy: 0.6732 - val_loss: 1.2097 - val_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# 4) Fit\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_wine_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_wine_class_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_wine_class_model.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 891us/step - loss: 1.7232 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7231839895248413, 0.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = [np.argmax(i) for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=int32, numpy=\n",
       "array([[ 0,  1,  1,  0,  0,  0],\n",
       "       [ 0,  0,  3,  3,  0,  0],\n",
       "       [ 0,  0, 97, 51,  0,  0],\n",
       "       [ 0,  0, 33, 83,  9,  0],\n",
       "       [ 0,  0,  3, 21, 11,  0],\n",
       "       [ 0,  0,  1,  0,  3,  0]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(labels=y_test, predictions=y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
    "corr_x = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(corr_x, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.savefig(\"corr-mat.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
